load arguments: {'training_data': '../../OntologySummit/AirlinesCustomerSatisfaction/EntityAlignment/', 'output': '../../OntologySummit/AirlinesCustomerSatisfaction/EntityAlignment/results/', 'dataset_division': '541_5fold', 'embedding_module': 'ProjE', 'alignment_module': 'sharing', 'search_module': 'greedy', 'dim': 100, 'init': 'xavier', 'ent_l2_norm': True, 'rel_l2_norm': True, 'learning_rate': 0.001, 'optimizer': 'Adam', 'max_epoch': 2000, 'batch_size': 500, 'dnn_neg_nums': 4096, 'batch_threads_num': 2, 'test_threads_num': 2, 'ordered': True, 'start_valid': 100, 'eval_freq': 10, 'stop_metric': 'hits1', 'eval_metric': 'inner', 'csls': 10, 'top_k': [1, 5, 10, 50], 'is_save': True, 'eval_norm': True}
ProjE
<openea.modules.args.args_hander.ARGs object at 0x7f973ebf08d0>
read relation triples: ../../OntologySummit/AirlinesCustomerSatisfaction/EntityAlignment/LLM-LLM/rel_triples_1
read relation triples: ../../OntologySummit/AirlinesCustomerSatisfaction/EntityAlignment/LLM-LLM/rel_triples_2
read attribute triples: ../../OntologySummit/AirlinesCustomerSatisfaction/EntityAlignment/LLM-LLM/attr_triples_1
read attribute triples: ../../OntologySummit/AirlinesCustomerSatisfaction/EntityAlignment/LLM-LLM/attr_triples_2
read links: ../../OntologySummit/AirlinesCustomerSatisfaction/EntityAlignment/LLM-LLM/541_5fold/1/train_links
read links: ../../OntologySummit/AirlinesCustomerSatisfaction/EntityAlignment/LLM-LLM/541_5fold/1/valid_links
read links: ../../OntologySummit/AirlinesCustomerSatisfaction/EntityAlignment/LLM-LLM/541_5fold/1/test_links
Number of rt_dict: 60000
Number of hr_dict: 3
entity relations dict: 60000
Number of av_dict: 60000
entity attributes dict: 60000

KG statistics:
Number of entities: 60003
Number of relations: 1
Number of attributes: 23
Number of relation triples: 60000
Number of attribute triples: 459923
Number of local relation triples: 60000
Number of local attribute triples: 459923

Number of rt_dict: 60000
Number of hr_dict: 3
entity relations dict: 60000
Number of av_dict: 60000
entity attributes dict: 60000

KG statistics:
Number of entities: 60003
Number of relations: 1
Number of attributes: 23
Number of relation triples: 60000
Number of attribute triples: 459923
Number of local relation triples: 60000
Number of local attribute triples: 459923

Number of rt_dict: 60000
Number of hr_dict: 3
entity relations dict: 60000
Number of av_dict: 60000
entity attributes dict: 60000

KG statistics:
Number of entities: 60003
Number of relations: 1
Number of attributes: 23
Number of relation triples: 60000
Number of attribute triples: 459923
Number of local relation triples: 60000
Number of local attribute triples: 459923

Number of rt_dict: 60000
Number of hr_dict: 3
entity relations dict: 60000
Number of av_dict: 60000
entity attributes dict: 60000

KG statistics:
Number of entities: 60003
Number of relations: 1
Number of attributes: 23
Number of relation triples: 60000
Number of attribute triples: 459923
Number of local relation triples: 60000
Number of local attribute triples: 459923

../../OntologySummit/AirlinesCustomerSatisfaction/EntityAlignment/results/ ../../OntologySummit/AirlinesCustomerSatisfaction/EntityAlignment/LLM-LLM/ ['..', '..', 'OntologySummit', 'AirlinesCustomerSatisfaction', 'EntityAlignment', 'LLM-LLM'] 541_5fold/1/ ProjE
results output folder: ../../OntologySummit/AirlinesCustomerSatisfaction/EntityAlignment/results/ProjE/LLM-LLM/541_5fold/1/20231111005855/
epoch 1, avg. triple loss: 7398.4745, cost time: 99.0757s
epoch 2, avg. triple loss: 2564.3178, cost time: 100.0937s
epoch 3, avg. triple loss: 730.9998, cost time: 96.7321s
epoch 4, avg. triple loss: 211.2723, cost time: 97.7094s
epoch 5, avg. triple loss: 79.4554, cost time: 89.5991s
epoch 6, avg. triple loss: 40.2105, cost time: 88.3917s
epoch 7, avg. triple loss: 25.3174, cost time: 92.2047s
epoch 8, avg. triple loss: 17.7600, cost time: 93.9231s
epoch 9, avg. triple loss: 13.4559, cost time: 92.9547s
epoch 10, avg. triple loss: 10.5152, cost time: 94.7776s
epoch 11, avg. triple loss: 8.3710, cost time: 99.8431s
epoch 12, avg. triple loss: 6.8881, cost time: 101.6774s
epoch 13, avg. triple loss: 5.8391, cost time: 97.6738s
epoch 14, avg. triple loss: 5.0261, cost time: 96.6276s
epoch 15, avg. triple loss: 4.3899, cost time: 92.0780s
epoch 16, avg. triple loss: 3.8958, cost time: 90.8584s
epoch 17, avg. triple loss: 3.4954, cost time: 92.4243s
epoch 18, avg. triple loss: 3.1830, cost time: 94.0669s
epoch 19, avg. triple loss: 2.9214, cost time: 94.5078s
epoch 20, avg. triple loss: 2.7120, cost time: 92.7968s
epoch 21, avg. triple loss: 2.5223, cost time: 90.5219s
epoch 22, avg. triple loss: 2.3685, cost time: 95.6778s
epoch 23, avg. triple loss: 2.2425, cost time: 98.0810s
epoch 24, avg. triple loss: 2.1356, cost time: 107.4120s
epoch 25, avg. triple loss: 2.0415, cost time: 103.5406s
epoch 26, avg. triple loss: 1.9632, cost time: 97.1852s
epoch 27, avg. triple loss: 1.8981, cost time: 98.7528s
epoch 28, avg. triple loss: 1.8366, cost time: 92.1785s
epoch 29, avg. triple loss: 1.7901, cost time: 88.2155s
epoch 30, avg. triple loss: 1.7431, cost time: 89.1941s
epoch 31, avg. triple loss: 1.7069, cost time: 91.4239s
epoch 32, avg. triple loss: 1.6781, cost time: 88.1599s
epoch 33, avg. triple loss: 1.6431, cost time: 90.5985s
epoch 34, avg. triple loss: 1.6218, cost time: 88.2127s
epoch 35, avg. triple loss: 1.6008, cost time: 97.4643s
epoch 36, avg. triple loss: 1.5809, cost time: 91.1822s
epoch 37, avg. triple loss: 1.5640, cost time: 97.4793s
epoch 38, avg. triple loss: 1.5500, cost time: 100.4585s
epoch 39, avg. triple loss: 1.5392, cost time: 94.1607s
epoch 40, avg. triple loss: 1.5260, cost time: 90.4983s
epoch 41, avg. triple loss: 1.5169, cost time: 93.4395s
epoch 42, avg. triple loss: 1.5080, cost time: 86.7589s
epoch 43, avg. triple loss: 1.4999, cost time: 91.0602s
epoch 44, avg. triple loss: 1.4950, cost time: 89.8272s
epoch 45, avg. triple loss: 1.4855, cost time: 91.7767s
epoch 46, avg. triple loss: 1.4814, cost time: 90.5815s
epoch 47, avg. triple loss: 1.4740, cost time: 94.4835s
epoch 48, avg. triple loss: 1.4722, cost time: 94.1556s
epoch 49, avg. triple loss: 1.4674, cost time: 96.4294s
epoch 50, avg. triple loss: 1.4643, cost time: 95.6436s
epoch 51, avg. triple loss: 1.4606, cost time: 92.2309s
epoch 52, avg. triple loss: 1.4602, cost time: 91.5925s
epoch 53, avg. triple loss: 1.4556, cost time: 91.4742s
epoch 54, avg. triple loss: 1.4547, cost time: 93.3786s
epoch 55, avg. triple loss: 1.4513, cost time: 91.3591s
epoch 56, avg. triple loss: 1.4482, cost time: 91.0571s
epoch 57, avg. triple loss: 1.4479, cost time: 89.5769s
epoch 58, avg. triple loss: 1.4443, cost time: 90.8034s
epoch 59, avg. triple loss: 1.4460, cost time: 87.3073s
epoch 60, avg. triple loss: 1.4422, cost time: 94.7885s
epoch 61, avg. triple loss: 1.4402, cost time: 92.1330s
epoch 62, avg. triple loss: 1.4395, cost time: 93.6161s
epoch 63, avg. triple loss: 1.4389, cost time: 94.6724s
epoch 64, avg. triple loss: 1.4385, cost time: 89.6132s
epoch 65, avg. triple loss: 1.4366, cost time: 93.3039s
epoch 66, avg. triple loss: 1.4379, cost time: 95.3553s
epoch 67, avg. triple loss: 1.4383, cost time: 98.5475s
epoch 68, avg. triple loss: 1.4339, cost time: 88.2008s
epoch 69, avg. triple loss: 1.4338, cost time: 85.4556s
epoch 70, avg. triple loss: 1.4332, cost time: 87.7929s
epoch 71, avg. triple loss: 1.4319, cost time: 86.2413s
epoch 72, avg. triple loss: 1.4312, cost time: 86.8724s
epoch 73, avg. triple loss: 1.4319, cost time: 92.3737s
epoch 74, avg. triple loss: 1.4297, cost time: 91.0503s
epoch 75, avg. triple loss: 1.4295, cost time: 93.8745s
epoch 76, avg. triple loss: 1.4280, cost time: 89.3606s
epoch 77, avg. triple loss: 1.4281, cost time: 85.9371s
epoch 78, avg. triple loss: 1.4270, cost time: 90.6298s
epoch 79, avg. triple loss: 1.4271, cost time: 90.8123s
epoch 80, avg. triple loss: 1.4270, cost time: 95.0065s
epoch 81, avg. triple loss: 1.4266, cost time: 93.9849s
epoch 82, avg. triple loss: 1.4258, cost time: 90.8036s
epoch 83, avg. triple loss: 1.4256, cost time: 87.6454s
epoch 84, avg. triple loss: 1.4249, cost time: 89.8663s
epoch 85, avg. triple loss: 1.4239, cost time: 87.0403s
epoch 86, avg. triple loss: 1.4261, cost time: 93.2486s
epoch 87, avg. triple loss: 1.4241, cost time: 94.3665s
epoch 88, avg. triple loss: 1.4249, cost time: 92.1380s
epoch 89, avg. triple loss: 1.4226, cost time: 88.6328s
epoch 90, avg. triple loss: 1.4241, cost time: 84.7808s
epoch 91, avg. triple loss: 1.4231, cost time: 86.2811s
epoch 92, avg. triple loss: 1.4220, cost time: 90.0029s
epoch 93, avg. triple loss: 1.4217, cost time: 89.3475s
epoch 94, avg. triple loss: 1.4216, cost time: 82.8820s
epoch 95, avg. triple loss: 1.4212, cost time: 81.5749s
epoch 96, avg. triple loss: 1.4194, cost time: 84.0754s
epoch 97, avg. triple loss: 1.4205, cost time: 83.8678s
epoch 98, avg. triple loss: 1.4212, cost time: 85.5050s
epoch 99, avg. triple loss: 1.4207, cost time: 78.9675s
epoch 100, avg. triple loss: 1.4209, cost time: 83.8643s
quick results: hits@[1, 5, 10, 50] = [0.    0.05  0.083 0.45 ]%, time = 12.699 s 
epoch 101, avg. triple loss: 1.4202, cost time: 85.6164s
epoch 102, avg. triple loss: 1.4193, cost time: 81.8240s
epoch 103, avg. triple loss: 1.4193, cost time: 80.9807s
epoch 104, avg. triple loss: 1.4184, cost time: 82.2997s
epoch 105, avg. triple loss: 1.4193, cost time: 86.1815s
epoch 106, avg. triple loss: 1.4193, cost time: 87.7725s
epoch 107, avg. triple loss: 1.4198, cost time: 86.6538s
epoch 108, avg. triple loss: 1.4191, cost time: 83.2753s
epoch 109, avg. triple loss: 1.4167, cost time: 81.3421s
epoch 110, avg. triple loss: 1.4167, cost time: 79.4420s
quick results: hits@[1, 5, 10, 50] = [0.    0.033 0.05  0.417]%, time = 12.746 s 
epoch 111, avg. triple loss: 1.4164, cost time: 86.2553s
epoch 112, avg. triple loss: 1.4176, cost time: 83.8917s
epoch 113, avg. triple loss: 1.4177, cost time: 84.8759s
epoch 114, avg. triple loss: 1.4173, cost time: 85.3762s
epoch 115, avg. triple loss: 1.4166, cost time: 78.7380s
epoch 116, avg. triple loss: 1.4178, cost time: 80.9241s
epoch 117, avg. triple loss: 1.4169, cost time: 84.2806s
epoch 118, avg. triple loss: 1.4161, cost time: 80.9011s
epoch 119, avg. triple loss: 1.4156, cost time: 90.1299s
epoch 120, avg. triple loss: 1.4144, cost time: 87.5138s
quick results: hits@[1, 5, 10, 50] = [0.    0.05  0.1   0.383]%, time = 12.694 s 

 == should early stop == 

Training ends. Total time = 10928.094 s.
accurate results: hits@[1, 5, 10, 50] = [0.012 0.083 0.129 0.675]%, mr = 4071.547, mrr = 0.001280, time = 70.186 s 
accurate results with csls: csls=10, hits@[1, 5, 10, 50] = [0.021 0.071 0.158 0.646]%, mr = 4049.808, mrr = 0.001294, time = 102.597 s 
Results saved!
../../OntologySummit/AirlinesCustomerSatisfaction/EntityAlignment/results/ProjE/LLM-LLM/541_5fold/1/20231111005855/kg1_ent_ids saved.
../../OntologySummit/AirlinesCustomerSatisfaction/EntityAlignment/results/ProjE/LLM-LLM/541_5fold/1/20231111005855/kg2_ent_ids saved.
../../OntologySummit/AirlinesCustomerSatisfaction/EntityAlignment/results/ProjE/LLM-LLM/541_5fold/1/20231111005855/kg1_rel_ids saved.
../../OntologySummit/AirlinesCustomerSatisfaction/EntityAlignment/results/ProjE/LLM-LLM/541_5fold/1/20231111005855/kg2_rel_ids saved.
../../OntologySummit/AirlinesCustomerSatisfaction/EntityAlignment/results/ProjE/LLM-LLM/541_5fold/1/20231111005855/kg1_attr_ids saved.
../../OntologySummit/AirlinesCustomerSatisfaction/EntityAlignment/results/ProjE/LLM-LLM/541_5fold/1/20231111005855/kg2_attr_ids saved.
Embeddings saved!
Total run time = 11159.775 s.
