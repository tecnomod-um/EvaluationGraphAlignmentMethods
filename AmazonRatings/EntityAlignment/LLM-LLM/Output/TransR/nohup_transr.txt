load arguments: {'training_data': '../../OntologySummit/AmazonRatings/EntityAlignment/', 'output': '../../OntologySummit/AmazonRatings/EntityAlignment/results/', 'dataset_division': '541_5fold', 'embedding_module': 'TransR', 'alignment_module': 'sharing', 'search_module': 'greedy', 'dim': 100, 'init': 'normal', 'ent_l2_norm': True, 'rel_l2_norm': True, 'loss_norm': 'L2', 'margin': 1.5, 'loss': 'margin-based', 'neg_sampling': 'uniform', 'neg_triple_num': 1, 'learning_rate': 0.01, 'optimizer': 'Adagrad', 'max_epoch': 2000, 'batch_size': 5000, 'batch_threads_num': 2, 'test_threads_num': 4, 'ordered': True, 'start_valid': 100, 'eval_freq': 10, 'stop_metric': 'hits1', 'eval_metric': 'inner', 'csls': 10, 'top_k': [1, 5, 10, 50], 'is_save': True, 'eval_norm': False}
TransR
<openea.modules.args.args_hander.ARGs object at 0x7ff2452629b0>
read relation triples: ../../OntologySummit/AmazonRatings/EntityAlignment/LLM-LLM/rel_triples_1
read relation triples: ../../OntologySummit/AmazonRatings/EntityAlignment/LLM-LLM/rel_triples_2
read attribute triples: ../../OntologySummit/AmazonRatings/EntityAlignment/LLM-LLM/attr_triples_1
read attribute triples: ../../OntologySummit/AmazonRatings/EntityAlignment/LLM-LLM/attr_triples_2
read links: ../../OntologySummit/AmazonRatings/EntityAlignment/LLM-LLM/541_5fold/1/train_links
read links: ../../OntologySummit/AmazonRatings/EntityAlignment/LLM-LLM/541_5fold/1/valid_links
read links: ../../OntologySummit/AmazonRatings/EntityAlignment/LLM-LLM/541_5fold/1/test_links
Number of rt_dict: 40499
Number of hr_dict: 20502
entity relations dict: 40499
Number of av_dict: 40499
entity attributes dict: 40499

KG statistics:
Number of entities: 40502
Number of relations: 3
Number of attributes: 4
Number of relation triples: 80499
Number of attribute triples: 60499
Number of local relation triples: 80499
Number of local attribute triples: 60499

Number of rt_dict: 40499
Number of hr_dict: 20502
entity relations dict: 40499
Number of av_dict: 40499
entity attributes dict: 40499

KG statistics:
Number of entities: 40502
Number of relations: 3
Number of attributes: 4
Number of relation triples: 80499
Number of attribute triples: 60499
Number of local relation triples: 80499
Number of local attribute triples: 60499

Number of rt_dict: 40499
Number of hr_dict: 20502
entity relations dict: 40499
Number of av_dict: 40499
entity attributes dict: 40499

KG statistics:
Number of entities: 40502
Number of relations: 3
Number of attributes: 4
Number of relation triples: 80499
Number of attribute triples: 60499
Number of local relation triples: 80499
Number of local attribute triples: 60499

Number of rt_dict: 40499
Number of hr_dict: 20502
entity relations dict: 40499
Number of av_dict: 40499
entity attributes dict: 40499

KG statistics:
Number of entities: 40502
Number of relations: 3
Number of attributes: 4
Number of relation triples: 80499
Number of attribute triples: 60499
Number of local relation triples: 80499
Number of local attribute triples: 60499

../../OntologySummit/AmazonRatings/EntityAlignment/results/ ../../OntologySummit/AmazonRatings/EntityAlignment/LLM-LLM/ ['..', '..', 'OntologySummit', 'AmazonRatings', 'EntityAlignment', 'LLM-LLM'] 541_5fold/1/ TransR
results output folder: ../../OntologySummit/AmazonRatings/EntityAlignment/results/TransR/LLM-LLM/541_5fold/1/20231105201110/
epoch 1, avg. triple loss: 0.9600, cost time: 107.9810s
epoch 2, avg. triple loss: 0.7132, cost time: 120.0306s
epoch 3, avg. triple loss: 0.5108, cost time: 118.4469s
epoch 4, avg. triple loss: 0.3594, cost time: 120.0194s
epoch 5, avg. triple loss: 0.2825, cost time: 135.1564s
epoch 6, avg. triple loss: 0.2450, cost time: 140.3214s
epoch 7, avg. triple loss: 0.2159, cost time: 139.7693s
epoch 8, avg. triple loss: 0.1993, cost time: 147.0421s
epoch 9, avg. triple loss: 0.1862, cost time: 200.2387s
epoch 10, avg. triple loss: 0.1770, cost time: 184.0190s
epoch 11, avg. triple loss: 0.1714, cost time: 137.2440s
epoch 12, avg. triple loss: 0.1654, cost time: 165.4441s
epoch 13, avg. triple loss: 0.1593, cost time: 139.8445s
epoch 14, avg. triple loss: 0.1559, cost time: 137.3773s
epoch 15, avg. triple loss: 0.1507, cost time: 149.7151s
epoch 16, avg. triple loss: 0.1446, cost time: 142.3239s
epoch 17, avg. triple loss: 0.1429, cost time: 148.0316s
epoch 18, avg. triple loss: 0.1403, cost time: 149.4404s
epoch 19, avg. triple loss: 0.1371, cost time: 142.7018s
epoch 20, avg. triple loss: 0.1324, cost time: 134.2027s
epoch 21, avg. triple loss: 0.1315, cost time: 132.8645s
epoch 22, avg. triple loss: 0.1288, cost time: 121.0520s
epoch 23, avg. triple loss: 0.1272, cost time: 129.6474s
epoch 24, avg. triple loss: 0.1254, cost time: 136.8728s
epoch 25, avg. triple loss: 0.1223, cost time: 126.2037s
epoch 26, avg. triple loss: 0.1212, cost time: 129.6582s
epoch 27, avg. triple loss: 0.1178, cost time: 130.2748s
epoch 28, avg. triple loss: 0.1164, cost time: 129.0483s
epoch 29, avg. triple loss: 0.1138, cost time: 137.1774s
epoch 30, avg. triple loss: 0.1120, cost time: 140.9310s
epoch 31, avg. triple loss: 0.1092, cost time: 132.9625s
epoch 32, avg. triple loss: 0.1091, cost time: 136.3713s
epoch 33, avg. triple loss: 0.1077, cost time: 127.3827s
epoch 34, avg. triple loss: 0.1057, cost time: 109.5754s
epoch 35, avg. triple loss: 0.1021, cost time: 128.0254s
epoch 36, avg. triple loss: 0.1019, cost time: 117.0972s
epoch 37, avg. triple loss: 0.1003, cost time: 114.5156s
epoch 38, avg. triple loss: 0.0981, cost time: 131.0593s
epoch 39, avg. triple loss: 0.0964, cost time: 131.8241s
epoch 40, avg. triple loss: 0.0957, cost time: 129.9530s
epoch 41, avg. triple loss: 0.0935, cost time: 129.4960s
epoch 42, avg. triple loss: 0.0923, cost time: 123.6822s
epoch 43, avg. triple loss: 0.0906, cost time: 125.2411s
epoch 44, avg. triple loss: 0.0906, cost time: 124.4820s
epoch 45, avg. triple loss: 0.0886, cost time: 120.8909s
epoch 46, avg. triple loss: 0.0878, cost time: 127.2712s
epoch 47, avg. triple loss: 0.0855, cost time: 119.4930s
epoch 48, avg. triple loss: 0.0847, cost time: 113.4997s
epoch 49, avg. triple loss: 0.0826, cost time: 112.5783s
epoch 50, avg. triple loss: 0.0835, cost time: 118.7249s
epoch 51, avg. triple loss: 0.0817, cost time: 117.7396s
epoch 52, avg. triple loss: 0.0803, cost time: 113.0114s
epoch 53, avg. triple loss: 0.0794, cost time: 102.0100s
epoch 54, avg. triple loss: 0.0789, cost time: 115.9984s
epoch 55, avg. triple loss: 0.0778, cost time: 114.2428s
epoch 56, avg. triple loss: 0.0769, cost time: 112.8886s
epoch 57, avg. triple loss: 0.0750, cost time: 114.1692s
epoch 58, avg. triple loss: 0.0753, cost time: 125.3469s
epoch 59, avg. triple loss: 0.0749, cost time: 110.8816s
epoch 60, avg. triple loss: 0.0748, cost time: 110.8484s
epoch 61, avg. triple loss: 0.0728, cost time: 107.2024s
epoch 62, avg. triple loss: 0.0714, cost time: 113.8128s
epoch 63, avg. triple loss: 0.0715, cost time: 110.5224s
epoch 64, avg. triple loss: 0.0708, cost time: 110.6251s
epoch 65, avg. triple loss: 0.0697, cost time: 109.1666s
epoch 66, avg. triple loss: 0.0699, cost time: 140.5428s
epoch 67, avg. triple loss: 0.0694, cost time: 128.2626s
epoch 68, avg. triple loss: 0.0675, cost time: 124.2254s
epoch 69, avg. triple loss: 0.0674, cost time: 122.6996s
epoch 70, avg. triple loss: 0.0673, cost time: 124.0800s
epoch 71, avg. triple loss: 0.0670, cost time: 110.4641s
epoch 72, avg. triple loss: 0.0663, cost time: 115.6496s
epoch 73, avg. triple loss: 0.0662, cost time: 121.4934s
epoch 74, avg. triple loss: 0.0654, cost time: 122.7001s
epoch 75, avg. triple loss: 0.0650, cost time: 113.9009s
epoch 76, avg. triple loss: 0.0646, cost time: 119.0367s
epoch 77, avg. triple loss: 0.0634, cost time: 123.3129s
epoch 78, avg. triple loss: 0.0632, cost time: 112.0272s
epoch 79, avg. triple loss: 0.0631, cost time: 114.4578s
epoch 80, avg. triple loss: 0.0636, cost time: 126.1996s
epoch 81, avg. triple loss: 0.0625, cost time: 120.3794s
epoch 82, avg. triple loss: 0.0615, cost time: 120.3578s
epoch 83, avg. triple loss: 0.0622, cost time: 117.0136s
epoch 84, avg. triple loss: 0.0613, cost time: 115.3650s
epoch 85, avg. triple loss: 0.0608, cost time: 107.1762s
epoch 86, avg. triple loss: 0.0597, cost time: 111.8399s
epoch 87, avg. triple loss: 0.0596, cost time: 108.1119s
epoch 88, avg. triple loss: 0.0594, cost time: 109.5832s
epoch 89, avg. triple loss: 0.0591, cost time: 109.1079s
epoch 90, avg. triple loss: 0.0584, cost time: 102.3182s
epoch 91, avg. triple loss: 0.0592, cost time: 114.5163s
epoch 92, avg. triple loss: 0.0580, cost time: 107.1113s
epoch 93, avg. triple loss: 0.0584, cost time: 107.0100s
epoch 94, avg. triple loss: 0.0577, cost time: 110.1104s
epoch 95, avg. triple loss: 0.0573, cost time: 110.6233s
epoch 96, avg. triple loss: 0.0572, cost time: 105.8291s
epoch 97, avg. triple loss: 0.0567, cost time: 103.8148s
epoch 98, avg. triple loss: 0.0565, cost time: 122.5131s
epoch 99, avg. triple loss: 0.0568, cost time: 117.6853s
epoch 100, avg. triple loss: 0.0563, cost time: 106.6126s
quick results: hits@[1, 5, 10, 50] = [0.099 0.198 0.321 1.235]%, time = 19.865 s 
epoch 101, avg. triple loss: 0.0560, cost time: 114.4320s
epoch 102, avg. triple loss: 0.0558, cost time: 110.0718s
epoch 103, avg. triple loss: 0.0556, cost time: 116.8088s
epoch 104, avg. triple loss: 0.0554, cost time: 117.3144s
epoch 105, avg. triple loss: 0.0552, cost time: 113.5262s
epoch 106, avg. triple loss: 0.0547, cost time: 115.2492s
epoch 107, avg. triple loss: 0.0538, cost time: 116.8652s
epoch 108, avg. triple loss: 0.0544, cost time: 113.9467s
epoch 109, avg. triple loss: 0.0534, cost time: 115.5972s
epoch 110, avg. triple loss: 0.0537, cost time: 106.8497s
quick results: hits@[1, 5, 10, 50] = [0.099 0.222 0.346 1.309]%, time = 24.929 s 
epoch 111, avg. triple loss: 0.0536, cost time: 128.2585s
epoch 112, avg. triple loss: 0.0531, cost time: 115.2966s
epoch 113, avg. triple loss: 0.0534, cost time: 109.5827s
epoch 114, avg. triple loss: 0.0529, cost time: 119.3443s
epoch 115, avg. triple loss: 0.0529, cost time: 113.6415s
epoch 116, avg. triple loss: 0.0522, cost time: 134.1729s
epoch 117, avg. triple loss: 0.0524, cost time: 113.7794s
epoch 118, avg. triple loss: 0.0519, cost time: 117.9188s
epoch 119, avg. triple loss: 0.0517, cost time: 117.1994s
epoch 120, avg. triple loss: 0.0514, cost time: 119.5971s
quick results: hits@[1, 5, 10, 50] = [0.099 0.247 0.395 1.333]%, time = 16.138 s 

 == should early stop == 

Training ends. Total time = 14798.757 s.
accurate results: hits@[1, 5, 10, 50] = [0.068 0.253 0.438 1.685]%, mr = 5371.453, mrr = 0.002909, time = 101.575 s 
accurate results with csls: csls=10, hits@[1, 5, 10, 50] = [0.062 0.241 0.42  1.642]%, mr = 5375.423, mrr = 0.002802, time = 185.173 s 
Results saved!
../../OntologySummit/AmazonRatings/EntityAlignment/results/TransR/LLM-LLM/541_5fold/1/20231105201110/kg1_ent_ids saved.
../../OntologySummit/AmazonRatings/EntityAlignment/results/TransR/LLM-LLM/541_5fold/1/20231105201110/kg2_ent_ids saved.
../../OntologySummit/AmazonRatings/EntityAlignment/results/TransR/LLM-LLM/541_5fold/1/20231105201110/kg1_rel_ids saved.
../../OntologySummit/AmazonRatings/EntityAlignment/results/TransR/LLM-LLM/541_5fold/1/20231105201110/kg2_rel_ids saved.
../../OntologySummit/AmazonRatings/EntityAlignment/results/TransR/LLM-LLM/541_5fold/1/20231105201110/kg1_attr_ids saved.
../../OntologySummit/AmazonRatings/EntityAlignment/results/TransR/LLM-LLM/541_5fold/1/20231105201110/kg2_attr_ids saved.
Embeddings saved!
Total run time = 15201.994 s.
